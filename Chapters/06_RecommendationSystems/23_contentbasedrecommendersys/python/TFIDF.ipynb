{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('me', 2), ('Julie', 1), ('loves', 2), ('Linda', 1), ('than', 1), ('more', 1)]\n",
      "[('me', 2), ('Julie', 1), ('likes', 1), ('loves', 1), ('Jane', 1), ('than', 1), ('more', 1)]\n",
      "[('basketball', 1), ('baseball', 1), ('likes', 1), ('He', 1), ('than', 1), ('more', 1)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#examples taken from here: http://stackoverflow.com/a/1750187\n",
    "\n",
    "mydoclist = ['Julie loves me more than Linda loves me',\n",
    "'Jane likes me more than Julie loves me',\n",
    "'He likes basketball more than baseball']\n",
    "\n",
    "#mydoclist = ['sun sky bright', 'sun sun bright']\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    print tf.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]\n",
      "The doc is \"Julie loves me more than Linda loves me\"\n",
      "The tf vector for Document 1 is [2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1]\n",
      "The doc is \"Jane likes me more than Julie loves me\"\n",
      "The tf vector for Document 2 is [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "The doc is \"He likes basketball more than baseball\"\n",
      "The tf vector for Document 3 is [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "All combined, here is our master document term matrix: \n",
      "[[2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1], [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "import string #allows for format()\n",
    "    \n",
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "  return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "  return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(mydoclist)\n",
    "\n",
    "doc_term_matrix = []\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "for doc in mydoclist:\n",
    "    print 'The doc is \"' + doc + '\"'\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    print 'The tf vector for Document %d is [%s]' % ((mydoclist.index(doc)+1), tf_vector_string)\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "print 'All combined, here is our master document term matrix: '\n",
    "print doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old document term matrix: \n",
      "[[2 0 1 0 0 2 0 1 0 1 1]\n",
      " [2 0 1 0 1 1 1 0 0 1 1]\n",
      " [0 1 0 1 1 0 0 0 1 1 1]]\n",
      "\n",
      "A document term matrix with row-wise L2 norms of 1:\n",
      "[[ 0.57735027  0.          0.28867513  0.          0.          0.57735027\n",
      "   0.          0.28867513  0.          0.28867513  0.28867513]\n",
      " [ 0.63245553  0.          0.31622777  0.          0.31622777  0.31622777\n",
      "   0.31622777  0.          0.          0.31622777  0.31622777]\n",
      " [ 0.          0.40824829  0.          0.40824829  0.40824829  0.          0.\n",
      "   0.          0.40824829  0.40824829  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def l2_normalizer(vec):\n",
    "    denom = np.sum([el**2 for el in vec])\n",
    "    return [(el / math.sqrt(denom)) for el in vec]\n",
    "\n",
    "doc_term_matrix_l2 = []\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "\n",
    "print 'A regular old document term matrix: ' \n",
    "print np.matrix(doc_term_matrix)\n",
    "print '\\nA document term matrix with row-wise L2 norms of 1:'\n",
    "print np.matrix(doc_term_matrix_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]\n",
      "The inverse document frequency vector is [1.609438, 1.386294, 1.609438, 1.386294, 1.609438, 1.609438, 1.386294, 1.386294, 1.386294, 1.791759, 1.791759]\n"
     ]
    }
   ],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount +=1\n",
    "    return doccount \n",
    "\n",
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / 1+df)\n",
    "\n",
    "my_idf_vector = [idf(word, mydoclist) for word in vocabulary]\n",
    "\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "print 'The inverse document frequency vector is [' + ', '.join(format(freq, 'f') for freq in my_idf_vector) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]\n",
      "The inverse document frequency vector is [1.609438, 1.386294, 1.609438, 1.386294, 1.609438, 1.609438, 1.386294, 1.386294, 1.386294, 1.791759, 1.791759]\n"
     ]
    }
   ],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount +=1\n",
    "    return doccount \n",
    "\n",
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / 1+df)\n",
    "\n",
    "my_idf_vector = [idf(word, mydoclist) for word in vocabulary]\n",
    "\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "print 'The inverse document frequency vector is [' + ', '.join(format(freq, 'f') for freq in my_idf_vector) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def build_idf_matrix(idf_vector):\n",
    "    idf_mat = np.zeros((len(idf_vector), len(idf_vector)))\n",
    "    np.fill_diagonal(idf_mat, idf_vector)\n",
    "    return idf_mat\n",
    "\n",
    "my_idf_matrix = build_idf_matrix(my_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.60943791  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          1.38629436  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          1.60943791  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.38629436  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          1.60943791  0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          1.60943791\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   1.38629436  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   1.38629436  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.38629436  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.79175947  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.79175947]]\n"
     ]
    }
   ],
   "source": [
    "print my_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['me', 'basketball', 'Julie', 'baseball', 'likes', 'loves', 'Jane', 'Linda', 'He', 'than', 'more'])\n",
      "[[ 0.57211257  0.          0.28605628  0.          0.          0.57211257\n",
      "   0.          0.24639547  0.          0.31846153  0.31846153]\n",
      " [ 0.62558902  0.          0.31279451  0.          0.31279451  0.31279451\n",
      "   0.26942653  0.          0.          0.34822873  0.34822873]\n",
      " [ 0.          0.36063612  0.          0.36063612  0.41868557  0.          0.\n",
      "   0.          0.36063612  0.46611542  0.46611542]]\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix_tfidf = []\n",
    "\n",
    "#performing tf-idf matrix multiplication\n",
    "for tf_vector in doc_term_matrix:\n",
    "    doc_term_matrix_tfidf.append(np.dot(tf_vector, my_idf_matrix))\n",
    "\n",
    "#normalizing\n",
    "doc_term_matrix_tfidf_l2 = []\n",
    "for tf_vector in doc_term_matrix_tfidf:\n",
    "    doc_term_matrix_tfidf_l2.append(l2_normalizer(tf_vector))\n",
    "                                    \n",
    "print vocabulary\n",
    "print np.matrix(doc_term_matrix_tfidf_l2) # np.matrix() just to make it easier to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {u'me': 8, u'basketball': 1, u'julie': 4, u'baseball': 0, u'likes': 5, u'loves': 7, u'jane': 3, u'linda': 6, u'more': 9, u'than': 10, u'he': 2}\n",
      "[[ 0.          0.          0.          0.          0.28945906  0.\n",
      "   0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]\n",
      " [ 0.          0.          0.          0.41715759  0.3172591   0.3172591\n",
      "   0.          0.3172591   0.6345182   0.24637999  0.24637999]\n",
      " [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358\n",
      "   0.          0.          0.          0.28561676  0.28561676]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1)\n",
    "term_freq_matrix = count_vectorizer.fit_transform(mydoclist)\n",
    "print \"Vocabulary:\", count_vectorizer.vocabulary_\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(term_freq_matrix)\n",
    "\n",
    "tf_idf_matrix = tfidf.transform(term_freq_matrix)\n",
    "print tf_idf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.28945906  0.\n",
      "   0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]\n",
      " [ 0.          0.          0.          0.41715759  0.3172591   0.3172591\n",
      "   0.          0.3172591   0.6345182   0.24637999  0.24637999]\n",
      " [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358\n",
      "   0.          0.          0.          0.28561676  0.28561676]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(mydoclist)\n",
    "\n",
    "print tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
