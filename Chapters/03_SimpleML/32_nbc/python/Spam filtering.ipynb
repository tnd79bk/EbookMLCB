{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu trong ví dụ này được lấy trong [Exercise 6: Naive Bayes - Machine Learning - Andrew Ng](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex6/ex6.html).\n",
    "\n",
    "Trong ví dụ này, dữ liệu đã được xử lý, và là một tập con của cơ sở dữ liệu [Ling-Spam Dataset](http://csmining.org/index.php/ling-spam-datasets.html. \n",
    "\n",
    "#### Mô tả dữ liệu \n",
    "Tập dữ liệu này bao gồm tổng cộng 960 emails tiếng Anh, được tách thành tập training và test theo tỉ lệ 700:260, 50% trong mỗi tập là các spam emails. \n",
    "\n",
    "Dữ liệu trong cơ sở dữ liệu này đã được xử lý khá đẹp. Các quy tắc xử lý như sau: \n",
    "\n",
    "1. **Loại bỏ _stop words_**: Những từ xuất hiện thường xuyên trong bất kỳ văn bản nào như 'and', 'the', 'of', ... được loại bỏ. \n",
    "\n",
    "2. **Lemmatization**: Những từ có cùng 'gốc' được đưa về cùng loại. Ví dụ, 'include', 'includes', 'included' đều được đưa chung về 'include'. Tất cả các từ cũng đã được đưa về dạng ký tự thường (không phải HOA). \n",
    "\n",
    "3. **Loại bỏ _non-words_**: Số, dấu câu, ký tự 'tabs', ký tự 'xuống dòng' đã được loại bỏ. \n",
    "\n",
    "Dưới đây là một ví dụ của 1 email không phải spam, **trước khi được xử lý**:\n",
    "```\n",
    "Subject: Re: 5.1344 Native speaker intuitions\n",
    "  \n",
    "The discussion on native speaker intuitions has been extremely interesting, but I worry that my brief intervention may have\n",
    "muddied the waters. I take it that there are a number of\n",
    "separable issues. The first is the extent to which a native\n",
    "speaker is likely to judge a lexical string as grammatical\n",
    "or ungrammatical per se. The second is concerned with the\n",
    "relationships between syntax and interpretation (although even\n",
    "here the distinction may not be entirely clear cut).\n",
    "```\n",
    "\n",
    "và **sau khi được xử lý**:\n",
    "```\n",
    "re native speaker intuition discussion native speaker intuition \n",
    "extremely interest worry brief intervention muddy waters number \n",
    "separable issue first extent native speaker likely judge lexical \n",
    "string grammatical ungrammatical per se second concern relationship \n",
    "between syntax interpretation although even here distinction entirely clear cut\n",
    "```\n",
    "\n",
    "Trong ví dụ này, chúng ta sẽ sử dụng Multinomial Naive Bayes.\n",
    "\n",
    "Để cho bài toán được đơn giản hơn, tôi tiếp tục sử dụng dữ liệu đã được xử lý, có thể được download ở đây: [ex6DataPrepared.zip](http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/exercises/ex6materials/ex6DataPrepared.zip). Trong folder sau khi giải nén, chúng ta sẽ thấy các files:\n",
    "```\n",
    "test-features.txt\n",
    "test-labels.txt\n",
    "train-features-50.txt\n",
    "train-features-100.txt\n",
    "train-features-400.txt\n",
    "train-features.txt\n",
    "train-labels-50.txt\n",
    "train-labels-100.txt\n",
    "train-labels-400.txt\n",
    "train-labels.txt\n",
    "```\n",
    "\n",
    "tương ứng với các file chứa dữ liệu của tập training và tập test. File `train-features-50.txt` chứa dữ liệu của tập training thu gọn với chỉ có tổng 50 training emails. \n",
    "\n",
    "Mỗi file `*labels*.txt` chứa nhiều dòng, mỗi dòng là một ký tự 0 hoặc 1 thể hiện email là _non-spam_ hoặc _spam_.\n",
    "\n",
    "Mỗi file `*features*.txt` chứa nhiều dòng, mỗi dòng có 3 số, ví dụ: \n",
    "\n",
    "```\n",
    "1 564 1\n",
    "1 19 2\n",
    "```\n",
    "trong đó số đầu tiên là chỉ số của email, bắt đầu từ 1; số thứ 2 là thứ tự của từ trong từ điển (tổng cộng 2500 từ); số thứ 3 là số lượng của từ đó trong email đang xét. Dòng đầu tiên nói rằng trong email thứ nhất, từ thứ 564 trong từ điển xuất hiện 1 lần. Cách lưu dữ liệu như thế này giúp tiết kiệm bộ nhớ vì 1 email thường không chứa hết tất cả các từ trong từ điển mà chỉ chứa một lượng nhỏ, ta chỉ cần lưu các giá trị khác không. \n",
    "\n",
    "Nếu ta biểu diễn feature vector của mỗi email là 1 vector hàng có độ dài bằng độ dài từ điển (2500) thì dòng thứ nhất nói rằng thành phần thứ 564 của vector này bằng 1. Tương tự, thành phần thứ 19 của vector này bằng 1. Nếu không xuất hiện, các thành phần khác được mặc định bằng 0. \n",
    "\n",
    "Dựa trên các thông tin này, chúng ta có thể tiến hành lập trình với thư viện sklearn.\n",
    "\n",
    "** Khai báo thư viện và đường dẫn tới file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## packages \n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix # for sparse matrix\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score # for evaluating results\n",
    "\n",
    "# data path and file name \n",
    "path = 'ex6DataPrepared/'\n",
    "train_data_fn = 'train-features.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "train_label_fn = 'train-labels.txt'\n",
    "test_label_fn = 'test-labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm số đọc dữ liệu từ file `data_fn` với labels tương ứng `label_fn`. Chú ý rằng [số lượng từ trong từ điển là 2500](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex6/ex6.html).\n",
    "\n",
    "Dữ liệu sẽ được lưu trong một ma trận mà mỗi hàng thể hiện một email. Ma trận này là ma trận sparse nên chúng ta sẽ sử dụng hàm [`scipy.sparse.coo_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = 2500 \n",
    "\n",
    "def read_data(data_fn, label_fn):\n",
    "    ## read label_fn\n",
    "    with open(path + label_fn) as f:\n",
    "        content = f.readlines()\n",
    "    label = [int(x.strip()) for x in content]\n",
    "\n",
    "    ## read data_fn\n",
    "    with open(path + data_fn) as f:\n",
    "        content = f.readlines()\n",
    "    # remove '\\n' at the end of each line\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "    dat = np.zeros((len(content), 3), dtype = int)\n",
    "    \n",
    "    for i, line in enumerate(content): \n",
    "        a = line.split(' ')\n",
    "        dat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\n",
    "    \n",
    "    # remember to -1 at coordinate since we're in Python\n",
    "    # check this: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html\n",
    "    # for more information about coo_matrix function \n",
    "    data = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)), shape=(len(label), nwords))\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc training data và test data, sử dụng class `MultinomialNB` trong sklearn để xây dựng mô hình và dự đoán đầu ra cho test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 700, accuracy = 98.08%\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử với các bộ dữ liệu training nhỏ hơn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 100, accuracy = 97.69%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-100.txt'\n",
    "train_label_fn = 'train-labels-100.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 50, accuracy = 97.31%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-50.txt'\n",
    "train_label_fn = 'train-labels-50.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy rằng thậm chí khi tập training là rất nhỏ, 50 emails tổng cộng, kết quả đạt được đã rất ấn tượng. \n",
    "\n",
    "Nếu bạn muốn tiếp tục thử mô hình `BernoulliNB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 50, accuracy = 69.62%\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(binarize = .5)\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy rằng trong bài toán này, `MultinomialNB` hoạt động hiệu quả hơn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
